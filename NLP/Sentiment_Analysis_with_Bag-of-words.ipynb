{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment_Analysis_with_Bag-of-words.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"PMbFDyaL-Qek","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":318},"outputId":"4cd52bba-2ed1-42cf-db2e-cfddc1777a0d","executionInfo":{"status":"ok","timestamp":1556822193910,"user_tz":240,"elapsed":231602,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}}},"source":["import torch.utils.data\n","import sklearn.metrics\n","import torch\n","import pandas\n","from torch.utils.data import Dataset\n","import tqdm\n","import spacy\n","import numpy as np\n","\n","from google.colab import files\n","import io\n","\n","\n","# nlp = spacy.load('en')\n","# nlp = spacy.load('en_core_web_lg')\n","\n","\n","!python -m spacy download en_core_web_lg\n","### This takes about 5 mins\n","\n","\n","# python -m spacy link en_core_web_lg en"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting en_core_web_lg==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz#egg=en_core_web_lg==2.0.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.0.0/en_core_web_lg-2.0.0.tar.gz (852.3MB)\n","\u001b[K     |████████████████████████████████| 852.3MB 1.2MB/s \n","\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n","  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-_ac7byix/wheels/0d/bc/67/e6a9108ab86cd076703af19ad4e0f02f57381ac6583df16249\n","Successfully built en-core-web-lg\n","Installing collected packages: en-core-web-lg\n","Successfully installed en-core-web-lg-2.0.0\n","\n","\u001b[93m    Linking successful\u001b[0m\n","    /usr/local/lib/python3.6/dist-packages/en_core_web_lg -->\n","    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_lg\n","\n","    You can now load the model via spacy.load('en_core_web_lg')\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NySJHOlg0mNM","colab_type":"code","colab":{}},"source":["nlp = spacy.load('en_core_web_lg')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qh1KkpTH1VkL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":932},"outputId":"25a9fffe-fdc5-491f-837f-869bac072568","executionInfo":{"status":"ok","timestamp":1556822229197,"user_tz":240,"elapsed":339,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}}},"source":["for token in nlp('hello'):\n","  print(token)\n","  print(token.vector)\n","  print(token.vector.shape)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["hello\n","[ 0.25233    0.10176   -0.67485    0.21117    0.43492    0.16542\n","  0.48261   -0.81222    0.041321   0.78502   -0.077857  -0.66324\n","  0.1464    -0.29289   -0.25488    0.019293  -0.20265    0.98232\n","  0.028312  -0.081276  -0.1214     0.13126   -0.17648    0.13556\n"," -0.16361   -0.22574    0.055006  -0.20308    0.20718    0.095785\n","  0.22481    0.21537   -0.32982   -0.12241   -0.40031   -0.079381\n"," -0.19958   -0.015083  -0.079139  -0.18132    0.20681   -0.36196\n"," -0.30744   -0.24422   -0.23113    0.09798    0.1463    -0.062738\n","  0.42934   -0.078038  -0.19627    0.65093   -0.22807   -0.30308\n"," -0.12483   -0.17568   -0.14651    0.15361   -0.29518    0.15099\n"," -0.51726   -0.033564  -0.23109   -0.7833     0.018029  -0.15719\n","  0.02293    0.49639    0.029225   0.05669    0.14616   -0.19195\n","  0.16244    0.23898    0.36431    0.45263    0.2456     0.23803\n","  0.31399    0.3487    -0.035791   0.56108   -0.25345    0.051964\n"," -0.10618   -0.30962    1.0585    -0.42025    0.18216   -0.11256\n","  0.40576    0.11784   -0.19705   -0.075292   0.080723  -0.02782\n"," -0.15617   -0.44681   -0.15165    0.1692     0.098255  -0.031894\n","  0.087143   0.26082    0.002706   0.1319     0.34439   -0.37894\n"," -0.4114     0.081571  -0.11674   -0.43711    0.011144   0.099353\n","  0.26612    0.40025    0.18895   -0.18438   -0.30355   -0.2725\n","  0.22468   -0.40614    0.15618   -0.16043    0.47147    0.0080203\n","  0.56858    0.21934   -0.11181    0.79925    0.10714   -0.50146\n","  0.063593   0.069465   0.15292   -0.2747    -0.20989    0.20737\n"," -0.10681    0.40651   -2.6438    -0.31139   -0.32157   -0.26458\n"," -0.35625    0.070013  -0.18838    0.48773   -0.26167   -0.020805\n","  0.17819    0.15758   -0.13752    0.056464   0.30766   -0.066136\n","  0.4748    -0.27335    0.09732   -0.20832    0.0039332  0.346\n"," -0.08702   -0.54924   -0.18759   -0.17174    0.060324  -0.13521\n","  0.10419    0.30165    0.05798    0.21872   -0.073594  -0.20423\n"," -0.25279   -0.10471   -0.32163    0.12525   -0.31281    0.0097207\n"," -0.26777   -0.61121   -0.11089   -0.13652    0.035135  -0.4939\n","  0.084857  -0.15494   -0.063509  -0.23935    0.28272    0.10849\n"," -0.3365    -0.60764    0.38576   -0.0095438  0.17499   -0.52723\n","  0.62211    0.19544   -0.48977    0.036582  -0.128     -0.016827\n","  0.25647   -0.31698    0.48257   -0.14184    0.11046   -0.3098\n"," -0.63141   -0.37268    0.23183   -0.14268   -0.02341    0.022255\n"," -0.044662  -0.16404   -0.25848    0.1629     0.024751   0.23348\n","  0.27933    0.38998   -0.058968   0.11355    0.15673    0.18583\n"," -0.19814   -0.48123   -0.035084   0.078458  -0.49833    0.10855\n"," -0.20133    0.05292   -0.11583   -0.16009    0.16768    0.42362\n"," -0.23106    0.082465   0.24296   -0.16786    0.0080409  0.085947\n","  0.38033    0.072981   0.1633     0.24704   -0.11094    0.15115\n"," -0.22068   -0.061944  -0.037091  -0.087923  -0.23181    0.15035\n"," -0.19093   -0.19113   -0.11894    0.094908  -0.0043347  0.15362\n"," -0.41201   -0.3073     0.18375    0.40206   -0.0034793 -0.10917\n"," -0.69522    0.10161   -0.079256   0.40329    0.22285   -0.19374\n"," -0.13315    0.073231   0.099832   0.11685   -0.21643   -0.1108\n","  0.10341    0.097286   0.11196   -0.3894    -0.0089363  0.28809\n"," -0.10792    0.028811   0.32545    0.26052   -0.038941   0.075204\n","  0.46031   -0.06293    0.21661    0.17869   -0.51917    0.33591  ]\n","(300,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DAdTD55OErpJ","colab_type":"code","outputId":"083d8c88-a413-48c5-b713-5068055802a9","executionInfo":{"status":"ok","timestamp":1556822300692,"user_tz":240,"elapsed":21910,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":75}},"source":["uploaded = files.upload()\n","\n","look = pandas.read_csv(io.BytesIO(uploaded['train.tsv']),sep='\\t', header=0)\n","## tsv is tab seperated data"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-f7d094fd-c72c-4a17-abe5-208a64463c69\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-f7d094fd-c72c-4a17-abe5-208a64463c69\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving train.tsv to train.tsv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8y06Z_OKC8Mh","colab_type":"code","outputId":"7e2e2b00-2341-4d30-b701-6ece10e6f797","executionInfo":{"status":"ok","timestamp":1556822386020,"user_tz":240,"elapsed":288,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":125}},"source":["print(look.iloc[0]) ### this is the full entry in the tsv\n","print(look.iloc[0][0]) ## this is the sentence entry\n","print(look.iloc[0][1]) ## this is the rating"],"execution_count":11,"outputs":[{"output_type":"stream","text":["a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films    apparently reassembled from the cutting room f...\n","1                                                                                                                                                          0\n","Name: 0, dtype: object\n","apparently reassembled from the cutting room floor of any given daytime soap\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h0eFzY3WKZC3","colab_type":"code","outputId":"ea7c1ad5-1426-486f-8c19-0d19809ca892","executionInfo":{"status":"ok","timestamp":1556822391983,"user_tz":240,"elapsed":269,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(look)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6919"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"K7n_W6k_KY7H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkwyMmWgDRbV","colab_type":"code","colab":{}},"source":["### \n","\n","\n","class SentimentDataset(Dataset):\n","  def __init__(self):\n","#     self.data = pandas\\\n","#     .read_csv('sentiment.tsv',sep='\\t', header = 0). groupby('SentenceId').first()\n","    self.data = pandas.read_csv(io.BytesIO(uploaded['train.tsv']),sep='\\t', header=0)\n","    \n","\n","    \n","    self.ordinals = {}\n","    for sample in range(len(self.data)):\n","      for token in nlp(self.data.iloc[sample][0], disable=['parser','tagger','ner']):\n","        if token.text not in self.ordinals:\n","          self.ordinals[token.text] = len(self.ordinals)\n","\n","\n","  def __len__(self):\n","    return len(self.data)\n","  \n","  \n","  def __getitem__(self,idx):\n","\n","    if type(idx) is torch.Tensor:\n","      idx = idx.item()\n","\n","    sample = self.data.iloc[idx]\n","    token_vectors = []\n","    \n","    for token in nlp(sample[0], disable=['parser','tagger','ner']):\n","      token_vectors.append(token.vector)\n","      \n","      \n","#     torch.tensor(sample[1])) - this is the sentiment\n","    return (torch.tensor(token_vectors), torch.tensor(len(token_vectors)), torch.tensor(sample[1]))\n","\n","  \n","\n","\n","### the group by is the review part of the data, without being interested in th dataset\n","### when \n","\n","sentiment = SentimentDataset()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pr453l37I7sp","colab_type":"code","outputId":"5c6633f2-e616-4ecb-d879-53427d177fbd","executionInfo":{"status":"ok","timestamp":1556823054788,"user_tz":240,"elapsed":428,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["sentiment.data.iloc[0][1]\n","sentiment[0]"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0.0264,  0.0534, -0.1999,  ..., -0.0585, -0.0613, -0.1719],\n","         [ 0.9621, -0.1497,  0.0861,  ..., -0.0636, -0.6391,  0.1251],\n","         [ 0.0133, -0.0511, -0.1321,  ...,  0.0640, -0.5301,  0.1901],\n","         ...,\n","         [-0.1236,  0.0720,  0.0314,  ..., -0.2018,  0.1018, -0.0100],\n","         [ 0.3811,  0.1144, -0.0188,  ..., -0.4154, -0.2239, -0.2230],\n","         [-0.2226, -0.1851,  0.0212,  ..., -0.8747, -0.1474,  0.1266]]),\n"," tensor(12),\n"," tensor(0))"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"o2M6dA45Q5Ch","colab_type":"code","outputId":"5e27200c-4f60-46c5-c1ef-c7d956e1e409","executionInfo":{"status":"ok","timestamp":1556823317913,"user_tz":240,"elapsed":298,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["### We can look at how many entries are in the on ehot vector - how big is our dictionary\n","## he called this how many features we have\n","\n","len (sentiment.ordinals)\n","len(sentiment)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6919"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"ok6OUyfB5rJq","colab_type":"code","colab":{}},"source":["def collate(batch):\n","  \n","  batch.sort(key=lambda x: x[1], reverse = True)\n","  sequences,lengths, sentiments = zip(*batch)\n","  sequences = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n","#   print(sentiments)\n","  sentiments = torch.stack(sentiments)\n","  lengths = torch.stack(lengths)\n","  return sequences, lengths, sentiments\n","  \n","  \n","## this makes all the sentences in the same batch to be the same length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MN0xhxml5rBS","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dl8_6tZrTPsP","colab_type":"code","outputId":"77490f41-cfb5-489a-cd5e-165794af0f75","executionInfo":{"status":"ok","timestamp":1556823735860,"user_tz":240,"elapsed":178,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["number_for_testing = int(len(sentiment)*0.05)\n","number_for_training = len(sentiment) - number_for_testing \n","\n","train,test = torch.utils.data.random_split(sentiment, [number_for_training,number_for_testing])\n","\n","\n","# trainloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle = True)\n","# testloader = torch.utils.data.DataLoader(test, batch_size = 32, shuffle = True)\n","\n","trainloader = torch.utils.data.DataLoader(train, batch_size=32, shuffle = True, collate_fn = collate)\n","testloader = torch.utils.data.DataLoader(test, batch_size = 32, shuffle = True, collate_fn = collate)\n","\n","len(test), len(train)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(345, 6574)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"bqmUZyBsTmST","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"cafd868f-75e3-4fc2-c55a-249c302428d7","executionInfo":{"status":"ok","timestamp":1556823737089,"user_tz":240,"elapsed":255,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}}},"source":["### sentiment.data.Sentiment.unique()\n","## they had this in their dataset that had the 5 stars - this is just the labels for the 5 stars thing\n","\n","\n","for batch in trainloader:\n","  print(batch[0].shape, batch[1].shape,batch[2].shape)\n","  print(batch[1][0])\n","  break"],"execution_count":31,"outputs":[{"output_type":"stream","text":["torch.Size([32, 45, 300]) torch.Size([32]) torch.Size([32])\n","tensor(45)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vQy5NeJKT8Rd","colab_type":"code","outputId":"5f86d830-f9bb-4ab1-acab-b1360e943148","executionInfo":{"status":"ok","timestamp":1556825104508,"user_tz":240,"elapsed":324,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["class  Model(torch.nn.Module):\n","  \n","  def __init__(self, input_dimensions, size = 128, layers = 1):\n","    \n","    super().__init__()\n","    self.seq = torch.nn.LSTM(input_dimensions, size, layers)\n","    self.layer_one = torch.nn.Linear(size*layers, size)\n","    self.activation_one = torch.nn.ReLU()\n","    self.layer_two = torch.nn.Linear(size,size)\n","    self.activation_two = torch.nn.ReLU()\n","    self.shape_outputs = torch.nn.Linear (size,2) ## this is where we put the size of the number of sentiments vector\n","    ### Even though we only have one sentiment, there is a bug that requires us to put 2 here\n","    \n","\n","  def forward(self, inputs, lengths):\n","    \n","\n","    number_of_batches = lengths.shape[0]\n","    packed_inputs = torch.nn.utils.rnn.pack_padded_sequence(inputs, lengths, batch_first = True)\n","    \n","    buffer, (hidden, cell) = self.seq(packed_inputs)\n","    \n","#     print(hidden.shape)\n","    buffer = hidden.permute(1,0,2)\n","#     print(buffer.shape)\n","    buffer = buffer.contiguous().view(number_of_batches, -1)\n","#     print(buffer.shape)\n","\n","\n","    buffer = self.layer_one(buffer)\n","    buffer = self.activation_one(buffer)\n","    buffer = self.layer_two(buffer)\n","    buffer = self.activation_two(buffer)\n","    buffer = self.shape_outputs(buffer)\n","\n","    return buffer\n","  \n","  \n","model = Model(sentiment[0][0].shape[1])\n","\n","print(len(sentiment.ordinals))"],"execution_count":47,"outputs":[{"output_type":"stream","text":["13829\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KlvBrUQqVTHP","colab_type":"code","outputId":"11cda6a6-d5b1-44ba-8794-ec710494f4df","executionInfo":{"status":"ok","timestamp":1556825105310,"user_tz":240,"elapsed":265,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":158}},"source":["optimizer = torch.optim.Adam(model.parameters())\n","loss_function = torch.nn.CrossEntropyLoss()\n","model.train()\n"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (seq): LSTM(300, 128)\n","  (layer_one): Linear(in_features=128, out_features=128, bias=True)\n","  (activation_one): ReLU()\n","  (layer_two): Linear(in_features=128, out_features=128, bias=True)\n","  (activation_two): ReLU()\n","  (shape_outputs): Linear(in_features=128, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"GMeQJudyV3oS","colab_type":"code","outputId":"b831b4d0-3ee1-4823-d2e3-31edef99b4da","executionInfo":{"status":"ok","timestamp":1556825169555,"user_tz":240,"elapsed":19342,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["### He did 64 epochs\n","for epoch in range(1):\n","  losses = []\n","  \n","  for sequences, lengths, sentiments in tqdm.tqdm(trainloader):\n","    optimizer.zero_grad()\n","#     print((inputs.t().size()))\n","#     print(len(sentiments))\n","    results = model(sequences, lengths)\n","#     print(outputs.size())\n","#     print(results[:,0].size())\n","#     print(torch.Tensor([outputs.numpy()]).t().size())\n","    outputs1 = torch.Tensor([sentiments.numpy()]).t().long()\n","    \n","    loss = loss_function(results, sentiments)\n","    losses.append(loss.item())\n","    loss.backward()\n","    optimizer.step()\n","  print(\"Loss {}\".format(torch.tensor(losses).mean()))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["100%|██████████| 206/206 [00:18<00:00, 10.92it/s]"],"name":"stderr"},{"output_type":"stream","text":["Loss 0.4774051308631897\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Trq5GFeBXosh","colab_type":"code","outputId":"d5e5349d-99a1-4ff4-efa5-3b2608f69713","executionInfo":{"status":"ok","timestamp":1556825303185,"user_tz":240,"elapsed":860,"user":{"displayName":"Benjamin Bodner","photoUrl":"","userId":"00792548603420028130"}},"colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["#Not lets try to get the classification report\n","\n","\n","results_buffer = []\n","actual_buffer = []\n","with torch.no_grad():\n","  model.eval()\n","  for sequences, lengths, sentiments in testloader:\n","    results = model(sequences, lengths).argmax(dim=1).numpy()\n","    results_buffer.append(results)\n","    actual_buffer.append(sentiments)\n","    \n","    \n","    \n","print(sklearn.metrics.classification_report(np.concatenate(actual_buffer), np.concatenate(results_buffer)))"],"execution_count":54,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.77      0.78      0.78       166\n","           1       0.80      0.79      0.79       179\n","\n","   micro avg       0.79      0.79      0.79       345\n","   macro avg       0.79      0.79      0.79       345\n","weighted avg       0.79      0.79      0.79       345\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"w7UGa6fCbDo3","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}